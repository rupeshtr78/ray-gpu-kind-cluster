# Kubernetes Ray Cluster Deployment Repository

This repository provides all necessary scripts, charts, and configurations to deploy and manage a [Ray](https://ray.io/) cluster on Kubernetes using [KubeRay](https://github.com/ray-project/kuberay). It supports GPU workloads and includes advanced features such as Ray API servers, KubeRay operator management, and Ray Job deployments, specifically optimized for machine learning and AI applications.

## ğŸ›  Project Structure

```

â”œâ”€â”€ versions.mk # Version information and dependencies variable definitions
â”œâ”€â”€ ray-oss-chart/ # Chart and Dockerfile for open-source Ray deployments
â”‚ â”œâ”€â”€ script/ # Utility scripts & tests for the helm chart
â”‚ â”‚ â””â”€â”€ chart-test.sh # Chart testing script
â”‚ â”œâ”€â”€ ray-cluster/ # Helm chart to deploy Ray cluster via KubeRay
â”‚ â”‚ â”œâ”€â”€ .helmignore
â”‚ â”‚ â”œâ”€â”€ Chart.yaml
â”‚ â”‚ â”œâ”€â”€ README.md
â”‚ â”‚ â”œâ”€â”€ values.yaml # Default helm chart values
â”‚ â”‚ â””â”€â”€ templates/ # Helm template resources for Ray clusters
â”‚ â”‚ â”œâ”€â”€ \_helpers.tpl
â”‚ â”‚ â””â”€â”€ raycluster-cluster.yaml
â”‚ â”œâ”€â”€ ray-base-docker/
â”‚ â”‚ â””â”€â”€ Dockerfile # Base Docker image for Ray clusters
â”‚ â”œâ”€â”€ kuberay-operator/ # Helm chart for deploying KubeRay Operator
â”‚ â”‚ â”œâ”€â”€ templates/ # Helm templates for Operator deployments, roles and bindings
â”‚ â”‚ â”œâ”€â”€ crds/ # Kubernetes Custom Resource Definitions (Ray clusters, jobs, services)
â”‚ â”‚ â”œâ”€â”€ values.yaml # Default configuration values for operator
â”‚ â”‚ â”œâ”€â”€ Chart.yaml
â”‚ â”‚ â””â”€â”€ README.md
â”‚ â””â”€â”€ kuberay-apiserver/ # Helm chart for KubeRay API server deployment
â”‚ â”œâ”€â”€ templates/ # Helm templates for API server deployment & service
â”‚ â”œâ”€â”€ values.yaml # Default configuration values
â”‚ â”œâ”€â”€ Chart.yaml
â”‚ â””â”€â”€ README.md
â”œâ”€â”€ ray-cluster/ # Dockerfile, scripts, and configuration for custom Ray workload deployments
â”‚ â”œâ”€â”€ Dockerfile # Docker definition for Ray workloads
â”‚ â”œâ”€â”€ ray-cluster-values.yaml # Example Helm values for deploying a Ray cluster
â”‚ â”œâ”€â”€ ray-cluster.sh # Ray cluster management script
â”‚ â”œâ”€â”€ ray_install.sh # Installation script for Ray runtime
â”‚ â””â”€â”€ ray-jobs/ # Ray job definitions & examples
â”‚ â”œâ”€â”€ qwen2-serve.py # Example Ray Serve deployment
â”‚ â””â”€â”€ ray-pvc.yaml # Persistent volume claim for Ray jobs
â””â”€â”€ kind-gpu-cluster/ # KIND Kubernetes cluster tailored for GPU workload testing
â”œâ”€â”€ gpu-test.yaml
â”œâ”€â”€ hf-cache-test.yaml
â”œâ”€â”€ image-registry-test.yaml
â”œâ”€â”€ nvidia-device-plugin.yml
â”œâ”€â”€ plugin-cm-mixed.yaml
â”œâ”€â”€ plugin-cm.yaml
â”œâ”€â”€ pv-test.yaml
â”œâ”€â”€ runtime-class.yaml
â”œâ”€â”€ working.sh
â””â”€â”€ kind/ # Helper scripts to manage kind GPU-enabled cluster
â”œâ”€â”€ build-plugin.sh
â”œâ”€â”€ create-cluster.sh
â”œâ”€â”€ delete-cluster.sh
â”œâ”€â”€ install-plugin.sh
â”œâ”€â”€ test.sh
â””â”€â”€ scripts/ # Dedicated scripts for KIND cluster management
â”œâ”€â”€ build-kind-image.sh
â”œâ”€â”€ build-plugin-image.sh
â”œâ”€â”€ common.sh
â”œâ”€â”€ create-kind-cluster.sh
â”œâ”€â”€ delete-kind-cluster.sh
â”œâ”€â”€ kind-cluster-config.yaml
â”œâ”€â”€ load-plugin-image-into-kind.sh
â”œâ”€â”€ nvidia-operator.sh
â”œâ”€â”€ ray-operator-values.yaml
â”œâ”€â”€ ray-operator.sh
â””â”€â”€ hf-cache-pv/ # Example persistent volume manifests
â”œâ”€â”€ pv.yaml
â””â”€â”€ pvc.yaml

```

## ğŸš€ Getting Started

### Prerequisites

- Kubernetes compatible cluster (`kubectl`, `helm`)
- Docker installed and running
- For GPU workloads:
  - NVIDIA drivers
  - NVIDIA container toolkit

### Cluster Deployments

Please follow these guides:

- [Deploying Ray cluster using Helm charts (KubeRay)](ray-oss-chart/ray-cluster/README.md)
- [Deploying Kubray operator](ray-oss-chart/kuberay-operator/README.md)
- [Deploying Kuberay API server](ray-oss-chart/kuberay-apiserver/README.md)

### GPU Cluster Setup with KIND

For GPU workloads & tests, please check:

- [Kind GPU cluster setup](kind-gpu-cluster/kind/README.md)

Example commands:

```shell
# Creating the KIND GPU cluster
cd kind-gpu-cluster/kind && ./create-cluster.sh

# Deploying NVIDIA device plugin
kubectl apply -f nvidia-device-plugin.yml

# Deploy Ray Operator
./install-plugin.sh && ./ray-operator.sh
```

## ğŸ³ Building Custom Docker Images for Ray

Navigate to dedicated Dockerfile directories and use:

```shell
docker build -t your-ray-image:latest .
```

## ğŸ’» Running Example Ray Workloads

You can deploy Ray jobs and Ray Serve applications by running scripts under `ray-cluster/ray-jobs/`.

Example Ray Serve deployment:

```shell
ray submit ray-cluster/ray-jobs/qwen2-serve.py
```

## ğŸ“œ Version Management

Edit common versions in `versions.mk` file to maintain consistency across all project resources.

## âš™ï¸ Testing Helm Charts and Cluster Setup

- Test Helm chart deployments by running:

  ```shell
  cd ray-oss-chart/script
  ./chart-test.sh
  ```

- Verify GPU workloads using example manifests provided in `kind-gpu-cluster/` directory.

## ğŸš© Contributing

If you'd like to contribute, please open an issue or pull request with your suggestions or improvements.

## ğŸ“– Documentation & Resources

- [Ray Documentation](https://docs.ray.io)
- [KubeRay Operator](https://github.com/ray-project/kuberay)
- [Kind Kubernetes](https://kind.sigs.k8s.io)

## â¤ï¸ License

This project is licensed under [Apache 2.0 License](LICENSE).

```

```
