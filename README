# Kubernetes Ray Cluster Deployment Repository

This repository provides all necessary scripts, charts, and configurations to deploy and manage a [Ray](https://ray.io/) cluster on Kubernetes using [KubeRay](https://github.com/ray-project/kuberay). It supports GPU workloads and includes advanced features such as Ray API servers, KubeRay operator management, and Ray Job deployments, specifically optimized for machine learning and AI applications.

## 🛠 Project Structure

```

├── versions.mk # Version information and dependencies variable definitions
├── ray-oss-chart/ # Chart and Dockerfile for open-source Ray deployments
│ ├── script/ # Utility scripts & tests for the helm chart
│ │ └── chart-test.sh # Chart testing script
│ ├── ray-cluster/ # Helm chart to deploy Ray cluster via KubeRay
│ │ ├── .helmignore
│ │ ├── Chart.yaml
│ │ ├── README.md
│ │ ├── values.yaml # Default helm chart values
│ │ └── templates/ # Helm template resources for Ray clusters
│ │ ├── \_helpers.tpl
│ │ └── raycluster-cluster.yaml
│ ├── ray-base-docker/
│ │ └── Dockerfile # Base Docker image for Ray clusters
│ ├── kuberay-operator/ # Helm chart for deploying KubeRay Operator
│ │ ├── templates/ # Helm templates for Operator deployments, roles and bindings
│ │ ├── crds/ # Kubernetes Custom Resource Definitions (Ray clusters, jobs, services)
│ │ ├── values.yaml # Default configuration values for operator
│ │ ├── Chart.yaml
│ │ └── README.md
│ └── kuberay-apiserver/ # Helm chart for KubeRay API server deployment
│ ├── templates/ # Helm templates for API server deployment & service
│ ├── values.yaml # Default configuration values
│ ├── Chart.yaml
│ └── README.md
├── ray-cluster/ # Dockerfile, scripts, and configuration for custom Ray workload deployments
│ ├── Dockerfile # Docker definition for Ray workloads
│ ├── ray-cluster-values.yaml # Example Helm values for deploying a Ray cluster
│ ├── ray-cluster.sh # Ray cluster management script
│ ├── ray_install.sh # Installation script for Ray runtime
│ └── ray-jobs/ # Ray job definitions & examples
│ ├── qwen2-serve.py # Example Ray Serve deployment
│ └── ray-pvc.yaml # Persistent volume claim for Ray jobs
└── kind-gpu-cluster/ # KIND Kubernetes cluster tailored for GPU workload testing
├── gpu-test.yaml
├── hf-cache-test.yaml
├── image-registry-test.yaml
├── nvidia-device-plugin.yml
├── plugin-cm-mixed.yaml
├── plugin-cm.yaml
├── pv-test.yaml
├── runtime-class.yaml
├── working.sh
└── kind/ # Helper scripts to manage kind GPU-enabled cluster
├── build-plugin.sh
├── create-cluster.sh
├── delete-cluster.sh
├── install-plugin.sh
├── test.sh
└── scripts/ # Dedicated scripts for KIND cluster management
├── build-kind-image.sh
├── build-plugin-image.sh
├── common.sh
├── create-kind-cluster.sh
├── delete-kind-cluster.sh
├── kind-cluster-config.yaml
├── load-plugin-image-into-kind.sh
├── nvidia-operator.sh
├── ray-operator-values.yaml
├── ray-operator.sh
└── hf-cache-pv/ # Example persistent volume manifests
├── pv.yaml
└── pvc.yaml

```

## 🚀 Getting Started

### Prerequisites

- Kubernetes compatible cluster (`kubectl`, `helm`)
- Docker installed and running
- For GPU workloads:
  - NVIDIA drivers
  - NVIDIA container toolkit

### Cluster Deployments

Please follow these guides:

- [Deploying Ray cluster using Helm charts (KubeRay)](ray-oss-chart/ray-cluster/README.md)
- [Deploying Kubray operator](ray-oss-chart/kuberay-operator/README.md)
- [Deploying Kuberay API server](ray-oss-chart/kuberay-apiserver/README.md)

### GPU Cluster Setup with KIND

For GPU workloads & tests, please check:

- [Kind GPU cluster setup](kind-gpu-cluster/kind/README.md)

Example commands:

```shell
# Creating the KIND GPU cluster
cd kind-gpu-cluster/kind && ./create-cluster.sh

# Deploying NVIDIA device plugin
kubectl apply -f nvidia-device-plugin.yml

# Deploy Ray Operator
./install-plugin.sh && ./ray-operator.sh
```

## 🐳 Building Custom Docker Images for Ray

Navigate to dedicated Dockerfile directories and use:

```shell
docker build -t your-ray-image:latest .
```

## 💻 Running Example Ray Workloads

You can deploy Ray jobs and Ray Serve applications by running scripts under `ray-cluster/ray-jobs/`.

Example Ray Serve deployment:

```shell
ray submit ray-cluster/ray-jobs/qwen2-serve.py
```

## 📜 Version Management

Edit common versions in `versions.mk` file to maintain consistency across all project resources.

## ⚙️ Testing Helm Charts and Cluster Setup

- Test Helm chart deployments by running:

  ```shell
  cd ray-oss-chart/script
  ./chart-test.sh
  ```

- Verify GPU workloads using example manifests provided in `kind-gpu-cluster/` directory.

## 🚩 Contributing

If you'd like to contribute, please open an issue or pull request with your suggestions or improvements.

## 📖 Documentation & Resources

- [Ray Documentation](https://docs.ray.io)
- [KubeRay Operator](https://github.com/ray-project/kuberay)
- [Kind Kubernetes](https://kind.sigs.k8s.io)

## ❤️ License

This project is licensed under [Apache 2.0 License](LICENSE).

```

```
