image:
  repository: "10.0.0.213:5050/qwen2-serve-ray-2.4.1-py310"
  tag: "1.0.4"
  pullPolicy: IfNotPresent

head:
  rayStartParams:
    num-gpus: "1"
  resources:
    limits:
      cpu: "8"
      memory: "12G"
      nvidia.com/gpu: "1"
    requests:
      cpu: "8"
      memory: "12G"
      nvidia.com/gpu: "1"
  containerEnv:
    - name: HUGGINGFACE_HUB_CACHE
      value: /data/hf-cache/huggingface/hub
    - name: HUGGING_FACE_HUB_TOKEN
      value: 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
    - name: CUDA_HOME
      value: "/usr/local/cuda-12.4"
    - name: PYTHONPATH
      value: "$PYTHONPATH:/home/ray"
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1"
  volumeMounts:
    - name: hf-cache
      mountPath: /data/hf-cache
    - name: cuda
      mountPath: /usr/local/cuda-12.4
      readOnly: true
  volumes:
    - name: hf-cache
      persistentVolumeClaim:
        claimName: hf-cache-pvc
    - name: cuda
      hostPath:
        path: /usr/local/cuda-12.4

worker:
  rayStartParams:
    num-gpus: "1"
  resources:
    limits:
      cpu: "16"
      memory: "16G"
      nvidia.com/gpu: "1"
    requests:
      cpu: "16"
      memory: "16G"
      nvidia.com/gpu: "1"
  containerEnv:
    - name: HUGGINGFACE_HUB_CACHE
      value: /data/hf-cache/huggingface/hub
    - name: HUGGING_FACE_HUB_TOKEN
      value: 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
    - name: CUDA_HOME
      value: "/usr/local/cuda-12.4"
    - name: PYTHONPATH
      value: "$PYTHONPATH:/home/ray"
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1"
  volumeMounts:
    - name: hf-cache
      mountPath: /data/hf-cache
    - name: cuda
      mountPath: /usr/local/cuda-12.4
      readOnly: true
  volumes:
    - name: hf-cache
      persistentVolumeClaim:
        claimName: hf-cache-pvc
    - name: cuda
      hostPath:
        path: /usr/local/cuda-12.4

service:
  type: NodePort
#   ports:
#     - name: serve-http
#       port: 9023
#       targetPort: 9023
#       protocol: TCP
